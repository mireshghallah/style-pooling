{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import subprocess  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_doc_command(step, dire):\n",
    "\n",
    "    com = r\"\"\"../src/main.py \n",
    "            --dataset blogs_3dom_cleaned \n",
    "            --clean_mem_every 5 \n",
    "            --reset_output_dir \n",
    "            --classifier_dir ../pretrained_classifer/blogs_3dom_cleaned \n",
    "            --train_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "            --train_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.docs \n",
    "            --dev_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "            --dev_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.docs \n",
    "            --dev_trg_ref ../data/blogs_3dom_cleaned/dev_ref.txt \n",
    "            --src_vocab  ../data/blogs_3dom_cleaned/text.vocab \n",
    "            --trg_vocab  ../data/blogs_3dom_cleaned/doc.attr.vocab \n",
    "            --d_word_vec=128 \n",
    "            --d_model=512 \n",
    "            --log_every=100 \n",
    "            --eval_every=3000 \n",
    "            --ppl_thresh=10000 \n",
    "            --eval_bleu \n",
    "            --batch_size 32 \n",
    "            --valid_batch_size 128 \n",
    "            --patience 5 \n",
    "            --lr_dec 0.5 \n",
    "            --lr 0.001 \n",
    "            --dropout 0.3 \n",
    "            --max_len 10000 \n",
    "            --seed 0 \n",
    "            --beam_size 1 \n",
    "            --word_blank 0.2 \n",
    "            --word_dropout 0.1 \n",
    "            --word_shuffle 3 \n",
    "            --cuda \n",
    "            --anneal_epoch 5 \n",
    "            --temperature 0.01 \n",
    "            --klw 0.03 \n",
    "            --max_pool_k_size 1 \n",
    "            --bt \n",
    "            --lm \n",
    "            --gumbel_softmax \n",
    "            --avg_len \n",
    "            --run_classifier_doc_evaluation \n",
    "            --step {} \n",
    "            --no_styles 3 \n",
    "            --input_classifier_text ../{} \n",
    "            --input_doc_dict ../data/blogs_3dom_cleaned/doc.dict\"\"\".format(step,dire)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_entropy_command(step, dire):\n",
    "\n",
    "    com = r\"\"\"../src/main.py \n",
    "        --dataset blogs_3dom_cleaned \n",
    "        --clean_mem_every 5 \n",
    "        --reset_output_dir\n",
    "        --classifier_dir ../pretrained_classifer/blogs_3dom_cleaned \n",
    "        --train_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "        --train_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.attr \n",
    "        --dev_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "        --dev_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.attr \n",
    "        --dev_trg_ref ../data/blogs_3dom_cleaned/dev_ref.txt \n",
    "        --src_vocab  ../data/blogs_3dom_cleaned/text.vocab \n",
    "        --trg_vocab  ../data/blogs_3dom_cleaned/attr_disc.vocab \n",
    "        --d_word_vec=128 \n",
    "        --d_model=512 \n",
    "        --log_every=100 \n",
    "        --eval_every=3000 \n",
    "        --ppl_thresh=10000 \n",
    "        --eval_bleu \n",
    "        --batch_size 32 \n",
    "        --valid_batch_size 128 \n",
    "        --patience 5 \n",
    "        --lr_dec 0.5 \n",
    "        --lr 0.001\n",
    "        --dropout 0.3\n",
    "        --max_len 10000\n",
    "        --seed 0 \n",
    "        --beam_size 1 \n",
    "        --word_blank 0.2 \n",
    "        --word_dropout 0.1 \n",
    "        --word_shuffle 3 \n",
    "        --cuda \n",
    "        --anneal_epoch 5 \n",
    "        --temperature 0.01 \n",
    "        --klw 0.03\n",
    "        --max_pool_k_size 1\n",
    "        --bt\n",
    "        --lm \n",
    "        --gumbel_softmax\n",
    "        --avg_len\n",
    "        --run_classifier_avg_certainty\n",
    "        --step {}\n",
    "        --no_styles 3\n",
    "        --input_classifier_text ../{}\"\"\".format(step,dire)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confidence_ratio_command(step, dire):\n",
    "\n",
    "    com = r\"\"\"../src/main.py \n",
    "        --dataset blogs_2dom_cleaned \n",
    "        --clean_mem_every 5 \n",
    "        --reset_output_dir\n",
    "        --classifier_dir ../pretrained_classifer/blogs_3dom_cleaned \n",
    "        --train_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "        --train_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.attr \n",
    "        --dev_src_file ../data/blogs_3dom_cleaned/dev_drop_7.txt \n",
    "        --dev_trg_file ../data/blogs_3dom_cleaned/dev_drop_7.attr \n",
    "        --dev_trg_ref ../data/blogs_3dom_cleaned/dev_ref.txt \n",
    "        --src_vocab  ../data/blogs_3dom_cleaned/text.vocab \n",
    "        --trg_vocab  ../data/blogs_3dom_cleaned/attr_disc.vocab \n",
    "        --d_word_vec=128 \n",
    "        --d_model=512 \n",
    "        --log_every=100 \n",
    "        --eval_every=3000 \n",
    "        --ppl_thresh=10000 \n",
    "        --eval_bleu \n",
    "        --batch_size 32 \n",
    "        --valid_batch_size 128 \n",
    "        --patience 5 \n",
    "        --lr_dec 0.5 \n",
    "        --lr 0.001\n",
    "        --dropout 0.3\n",
    "        --max_len 10000\n",
    "        --seed 0 \n",
    "        --beam_size 1 \n",
    "        --word_blank 0.2 \n",
    "        --word_dropout 0.1 \n",
    "        --word_shuffle 3 \n",
    "        --cuda \n",
    "        --anneal_epoch 5 \n",
    "        --temperature 0.01 \n",
    "        --klw 0.03\n",
    "        --max_pool_k_size 1\n",
    "        --bt\n",
    "        --lm \n",
    "        --gumbel_softmax\n",
    "        --avg_len\n",
    "        --run_classifier_count_certainty\n",
    "        --step {}\n",
    "        --no_styles 3\n",
    "        --input_classifier_text ../{}\"\"\".format(step,dire)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confidence_ratio_command_2dom(step, dire):\n",
    "\n",
    "    com = r\"\"\"../src/main.py \n",
    "        --dataset blogs_2dom_cleaned \n",
    "        --clean_mem_every 5 \n",
    "        --reset_output_dir\n",
    "        --classifier_dir ../pretrained_classifer/blogs_3dom_cleaned \n",
    "        --train_src_file ../data/blogs_2dom_cleaned/dev_drop_10.txt \n",
    "        --train_trg_file ../data/blogs_2dom_cleaned/dev_drop_10_3dom.attr \n",
    "        --dev_src_file ../data/blogs_2dom_cleaned/dev_drop_10.txt \n",
    "        --dev_trg_file ../data/blogs_2dom_cleaned/dev_drop_10_3dom.attr \n",
    "        --dev_trg_ref ../data/blogs_3dom_cleaned/dev_ref.txt \n",
    "        --src_vocab  ../data/blogs_3dom_cleaned/text.vocab \n",
    "        --trg_vocab  ../data/blogs_3dom_cleaned/attr_disc.vocab \n",
    "        --d_word_vec=128 \n",
    "        --d_model=512 \n",
    "        --log_every=100 \n",
    "        --eval_every=3000 \n",
    "        --ppl_thresh=10000 \n",
    "        --eval_bleu \n",
    "        --batch_size 32 \n",
    "        --valid_batch_size 128 \n",
    "        --patience 5 \n",
    "        --lr_dec 0.5 \n",
    "        --lr 0.001\n",
    "        --dropout 0.3\n",
    "        --max_len 10000\n",
    "        --seed 0 \n",
    "        --beam_size 1 \n",
    "        --word_blank 0.2 \n",
    "        --word_dropout 0.1 \n",
    "        --word_shuffle 3 \n",
    "        --cuda \n",
    "        --anneal_epoch 5 \n",
    "        --temperature 0.01 \n",
    "        --klw 0.03\n",
    "        --max_pool_k_size 1\n",
    "        --bt\n",
    "        --lm \n",
    "        --gumbel_softmax\n",
    "        --avg_len\n",
    "        --run_classifier_count_certainty\n",
    "        --step {}\n",
    "        --no_styles 3\n",
    "        --input_classifier_text ../{}\"\"\".format(step,dire)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt_command_original(step, dire):\n",
    "\n",
    "    com = r\"\"\"/home/NAME/PROJECT/Deep-Learning/GPT2-HarryPotter-Training/examples/run_lm_finetuning.py\n",
    "        --output_dir=/home/NAME/PROJECT/Deep-Learning/GPT2-HarryPotter-Training/examples/output-original/checkpoint-1\n",
    "        --model_type=gpt2\n",
    "        --model_name_or_path=gpt2-medium\n",
    "        --train_data_file=/home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\n",
    "        --do_eval\n",
    "        --eval_data_file=/home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\n",
    "        --block_size=200\n",
    "        --per_gpu_train_batch_size=1\"\"\".format(dire,step,dire,step)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt_command_tuned(step, dire):\n",
    "\n",
    "    com = r\"\"\"/home/NAME/PROJECT/Deep-Learning/GPT2-HarryPotter-Training/examples/run_lm_finetuning.py\n",
    "        --output_dir=/home/NAME/PROJECT/Deep-Learning/GPT2-HarryPotter-Training/examples/output/checkpoint-290000\n",
    "        --model_type=gpt2\n",
    "        --model_name_or_path=gpt2-medium\n",
    "        --train_data_file=/home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\n",
    "        --do_eval\n",
    "        --eval_data_file=/home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\n",
    "        --block_size=200\n",
    "        --per_gpu_train_batch_size=1\"\"\".format(dire,step,dire,step)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_cmd(step, dire):\n",
    "\n",
    "    com = r\"\"\"split -l 19374 /home/NAME/PROJECT/style-pooling/{}/dev.trans_{} /home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\"\"\".format(dire,step,dire,step)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lexi_cmd(step, dire):\n",
    "\n",
    "    com = r\"\"\"../scripts/lexical_div.py --input /home/NAME/PROJECT/style-pooling/{}/dev.trans_{}\"\"\".format(dire,step)\n",
    "    return com\n",
    "\n",
    "#print (proc.communicate())"
   ]
  },
  {
   "source": [
    "# sum + onelm + min not distinguished [3dom data]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"93.78,93.56,92.63,90.5,86.09,85.11999999999999\",\",\")\n",
      "=SPLIT(\"45.226605119597146,45.02727654217373,45.05874947545111,44.99580360889635,43.62148552245069,44.02014267729753\",\",\")\n",
      "=SPLIT(\"44.41879983214436,44.3978178766261,44.25094418799832,43.915232899706254,42.93957196810743,43.1598825010491\",\",\")\n",
      "=SPLIT(\"48.91400382859667,49.12752171992343,48.95817994404359,49.07230157561479,48.115152407598295,48.44279193049624\",\",\")\n",
      "=SPLIT(\"1.3873950590039015,1.3858452169064166,1.3912851810806401,1.3911581160200308,1.4120996592059225,1.4110289489269747\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"60.855464983784735,60.73872609229689,61.101747538366006,60.7937200174444,60.104463437796774,60.22951744896999\",\",\")\n",
      "=SPLIT(\"42.00044176115447,41.959946988661464,41.49977911942276,42.20659696657341,38.764541304667944,39.136356943012814\",\",\")\n",
      "=SPLIT(\"46.2936,47.233,50.9922,51.2885,52.3022,50.271\",\",\")\n",
      "=SPLIT(\"2.0783409756138007,2.1377241561181433,2.1235186045103065,2.098585649025514,1.9749157226910112,2.0675448858145566\",\",\")\n",
      "=SPLIT(\"5013.0,5188.0,5259.0,5260.0,4716.0,4878.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"92.62,94.41000000000001,93.84,93.76,94.69,94.8\",\",\")\n",
      "=SPLIT(\"45.23709609735627,45.26856903063366,45.49937054133446,45.436424674779694,45.7511540075535,45.70919009651699\",\",\")\n",
      "=SPLIT(\"44.3978178766261,44.37683592110785,44.56567352077214,44.43978178766261,44.754511120436426,44.73352916491817\",\",\")\n",
      "=SPLIT(\"48.86614637019584,48.936091886320135,49.164335149462524,49.134884405831244,49.28950080989545,49.26005006626417\",\",\")\n",
      "=SPLIT(\"1.3800928197014475,1.37607512574469,1.3767194249390888,1.3717319880050054,1.375543686483802,1.3750201334677359\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"60.80882986979391,60.71428571428571,61.04502973661852,60.916554959785515,61.25105663567202,61.26179746620185\",\",\")\n",
      "=SPLIT(\"42.69253423648947,43.0864379325578,43.32940656751583,43.940509497864824,43.550287144750406,43.29627448093064\",\",\")\n",
      "=SPLIT(\"46.3038,47.9486,44.4387,44.108,44.6938,44.5705\",\",\")\n",
      "=SPLIT(\"2.2323100159450715,2.350599279188668,2.455094846399194,2.5352868656541174,2.5919251240301286,2.6591587174853974\",\",\")\n",
      "=SPLIT(\"5306.0,5609.0,5850.0,6046.0,6170.0,6328.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"87.31,89.25,88.83,88.64,87.88,88.3\",\",\")\n",
      "=SPLIT(\"42.84515316827529,43.07595467897608,43.180864456567356,43.44313890054553,43.212337389844734,43.26479227864037\",\",\")\n",
      "=SPLIT(\"41.83801930339908,42.05832983634075,42.131766680654636,42.320604280318925,42.10029374737726,42.530423835501466\",\",\")\n",
      "=SPLIT(\"47.17272861139744,47.13223383890443,47.23899278456781,47.10278309527315,47.110145781180975,47.246355470475635\",\",\")\n",
      "=SPLIT(\"1.44103682976797,1.440510348321552,1.4413006553206138,1.4428618784558878,1.441269491333583,1.4411305829327477\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"59.310272316265376,59.37142262462275,59.53998954521693,59.72135579122478,59.54222084751005,59.50576264147025\",\",\")\n",
      "=SPLIT(\"35.01325283463407,35.37402444411721,35.2120453541452,35.4071565307024,35.705345309969076,35.45501398910322\",\",\")\n",
      "=SPLIT(\"49.066,50.221,52.7754,53.8699,57.8508,58.4232\",\",\")\n",
      "=SPLIT(\"0.943831770829455,1.015939288805352,1.0610119158651872,1.1053464353980182,1.0932461433017606,1.1267584431615472\",\",\")\n",
      "=SPLIT(\"2535.0,2735.0,2844.0,2955.0,2919.0,2994.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"88.72,89.96,90.64,90.51,92.06,91.36\",\",\")\n",
      "=SPLIT(\"43.065463701216956,43.22282836760386,42.8136802349979,43.306756189676875,43.212337389844734,43.33822912295426\",\",\")\n",
      "=SPLIT(\"42.49895090222409,42.68778850188838,42.436005035669325,42.85564414603441,42.740243390684014,42.908099034830045\",\",\")\n",
      "=SPLIT(\"46.738330142836105,46.86717714622294,46.57266970991017,46.99602414960978,46.94080400530113,46.95921072007068\",\",\")\n",
      "=SPLIT(\"1.4314198788162746,1.4327458519416711,1.4252359547261864,1.4306384827949885,1.426122947112044,1.4256874809663964\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"57.991328022587474,58.491331237960054,57.59561772473833,58.382841607088906,58.097384148133635,58.296405711472175\",\",\")\n",
      "=SPLIT(\"36.50787807392137,36.309085554410245,37.6343690178177,36.5594168752761,37.575467530555144,37.38403769695185\",\",\")\n",
      "=SPLIT(\"74.3144,64.4877,69.1861,67.2911,67.7712,66.432\",\",\")\n",
      "=SPLIT(\"1.1793048434875675,1.2346647422421637,1.367327121340468,1.4087293576129527,1.4884620721742892,1.5393460939347725\",\",\")\n",
      "=SPLIT(\"2942.0,3148.0,3309.0,3489.0,3647.0,3775.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"83.66,84.24000000000001,82.86,83.59,83.46000000000001,83.39\",\",\")\n",
      "=SPLIT(\"40.610574905581196,40.77843054972723,40.98825010490978,41.261015526647085,40.673520772135966,40.85186739404112\",\",\")\n",
      "=SPLIT(\"40.18044481745699,40.26437263953,40.57910197230382,40.73646663869073,40.31682752832564,40.58959295006295\",\",\")\n",
      "=SPLIT(\"45.54189368281549,45.28051833308791,45.54189368281549,45.57502576940068,45.74804888823443,45.79222500368134\",\",\")\n",
      "=SPLIT(\"1.4851729182778535,1.4823886036890417,1.4846802594787751,1.4798587287337732,1.482459303522089,1.484074051505493\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"57.717466945024356,57.717480229070084,57.48865355521936,58.40347185691741,57.89966555183946,57.86342123056119\",\",\")\n",
      "=SPLIT(\"26.450449123840375,26.998969223972907,26.7670446178766,27.992931821528494,27.51803858047416,27.223531144161388\",\",\")\n",
      "=SPLIT(\"60.0055,63.2719,69.0363,68.8363,67.5686,66.4876\",\",\")\n",
      "=SPLIT(\"0.627110816037872,0.7123835134101183,0.6719213444151457,0.7305152984992235,0.7195480259022672,0.7375393604815267\",\",\")\n",
      "=SPLIT(\"1738.0,1918.0,1878.0,1985.0,1969.0,2012.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"85.91,86.52,85.72999999999999,86.72,87.18,87.83\",\",\")\n",
      "=SPLIT(\"40.631556861099455,40.89383130507763,40.89383130507763,40.746957616449855,41.219051615610574,41.806546370121694\",\",\")\n",
      "=SPLIT(\"40.27486361728913,40.48468317247168,40.58959295006295,40.4951741502308,40.704993705413344,41.407889215274864\",\",\")\n",
      "=SPLIT(\"44.941834781328225,44.95287881018996,45.103813871300254,45.16271535856281,45.530849653953766,45.41304667942865\",\",\")\n",
      "=SPLIT(\"1.4684713883527054,1.4604519414473416,1.4650842579277217,1.466800081205024,1.463888171564899,1.4651434150856455\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"54.69357976653697,54.16277985074627,55.83841281223856,55.60381228133671,55.6326237742167,56.451999042374915\",\",\")\n",
      "=SPLIT(\"30.275364452952434,31.57119717272861,30.801796495361504,30.514651744956563,30.783389780591957,30.75393903696068\",\",\")\n",
      "=SPLIT(\"81.8965,78.9201,74.9894,73.6099,68.4615,73.867\",\",\")\n",
      "=SPLIT(\"0.7692021711651423,0.8029269767973652,0.8256360713127113,0.8607645530590686,0.8745156842101531,0.9386078733637208\",\",\")\n",
      "=SPLIT(\"2069.0,2177.0,2316.0,2412.0,2467.0,2539.0\",\",\")\n",
      "********************\n",
      "=SPLIT(\"16500,18000,19500,21000,22500,24000\",\",\")\n",
      "=SPLIT(\"83.66,84.24000000000001,82.86,83.59,83.46000000000001,83.39\",\",\")\n",
      "=SPLIT(\"40.610574905581196,40.77843054972723,40.98825010490978,41.261015526647085,40.673520772135966,40.85186739404112\",\",\")\n",
      "=SPLIT(\"40.18044481745699,40.26437263953,40.57910197230382,40.73646663869073,40.31682752832564,40.58959295006295\",\",\")\n",
      "=SPLIT(\"45.54189368281549,45.28051833308791,45.54189368281549,45.57502576940068,45.74804888823443,45.79222500368134\",\",\")\n",
      "=SPLIT(\"1.4851729182778535,1.4823886036890417,1.4846802594787751,1.4798587287337732,1.482459303522089,1.484074051505493\",\",\")\n",
      "=SPLIT(\"0.0,0.0,0.0,0.0,0.0,0.0\",\",\")\n",
      "=SPLIT(\"57.717466945024356,57.717480229070084,57.48865355521936,58.40347185691741,57.89966555183946,57.86342123056119\",\",\")\n",
      "=SPLIT(\"26.450449123840375,26.998969223972907,26.7670446178766,27.992931821528494,27.51803858047416,27.223531144161388\",\",\")\n",
      "=SPLIT(\"60.0055,63.2719,69.0363,68.8363,67.5686,66.4876\",\",\")\n",
      "=SPLIT(\"0.627110816037872,0.7123835134101183,0.6719213444151457,0.7305152984992235,0.7195480259022672,0.7375393604815267\",\",\")\n",
      "=SPLIT(\"1738.0,1918.0,1878.0,1985.0,1969.0,2012.0\",\",\")\n",
      "********************\n",
      "6 6 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "val_step =[]\n",
    "classifier_acc = []\n",
    "n_acc = []\n",
    "bt_acc = []\n",
    "total_loss=[]\n",
    "neg_ELBO = []\n",
    "KL_loss=[]\n",
    "\n",
    "confidence_accuracy = []\n",
    "confidence_ratio = []\n",
    "\n",
    "\n",
    "cls_sent = []\n",
    "maj_doc = []\n",
    "sum_doc = []\n",
    "#\n",
    "log_paths=[\n",
    "    \"path to checkpoints\"\n",
    "]\n",
    "for log_path in log_paths:   \n",
    "    with open(\"../\"+log_path+\"/stdout\") as f:\n",
    "        val_step =[]\n",
    "        classifier_acc = []\n",
    "        n_acc = []\n",
    "        bt_acc = []\n",
    "        total_loss=[]\n",
    "        neg_ELBO = []\n",
    "        KL_loss=[]\n",
    "\n",
    "        cls_sent = []\n",
    "        maj_doc = []\n",
    "        sum_doc = []\n",
    "        entorpy = []\n",
    "        diff_per = []\n",
    "\n",
    "        gpt_original =[]\n",
    "        gpt_dom0_0 =[]\n",
    "        gpt_dom0_1 =[]\n",
    "        gpt_dom1_0 =[]\n",
    "        gpt_dom1_1 =[]\n",
    "        gpt_tuned =[]\n",
    "\n",
    "        lex_div = []\n",
    "        unique_words = []\n",
    "\n",
    "        confidence_accuracy = []\n",
    "        confidence_ratio = []\n",
    "        for i, line in enumerate(f):\n",
    "            if (\"classifier_acc=\" in line):\n",
    "                list_acc = re.findall(\"\\d+\\.\\d+\", line)\n",
    "                #print(list_acc)\n",
    "                classifier_acc.append(float(list_acc[0]))\n",
    "            elif (\"val_step\" in line):\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", line)\n",
    "                #print(list_arguments)\n",
    "                if (int(list_arguments[0]) >25000):\n",
    "                    continue\n",
    "                elif (int(list_arguments[0]) < 16500):\n",
    "                    continue\n",
    "                elif (int(list_arguments[0])% 1500 != 0):\n",
    "                    continue\n",
    "                val_step.append(int(list_arguments[0]))\n",
    "                total_loss.append(float(list_arguments[1]))\n",
    "                neg_ELBO.append(float(list_arguments[2]))\n",
    "                KL_loss.append(float(list_arguments[3]))\n",
    "                n_acc.append(float(list_arguments[6])*100)\n",
    "                bt_acc.append(float(list_arguments[7])*100)\n",
    "                \n",
    "                ###get acc nums\n",
    "                com = make_doc_command(str(val_step[-1]),log_path)\n",
    "                proc = subprocess.Popen([\"/home/NAME/anaconda3/envs/py37/bin/python\"]+(com.replace('\\n','').split()), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                outp = (proc.communicate())\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(outp[0]))\n",
    "                sum_doc.append(float(list_arguments[-3]))\n",
    "                maj_doc.append(float(list_arguments[-2]))\n",
    "                cls_sent.append(float(list_arguments[-1]))\n",
    "                #print(outp)\n",
    "                ## get entropy\n",
    "                com = make_entropy_command(str(val_step[-1]),log_path)\n",
    "                proc = subprocess.Popen([\"/home/NAME/anaconda3/envs/py37/bin/python\"]+(com.replace('\\n','').split()), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                outp = (proc.communicate())\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(outp[0]))\n",
    "                diff_per.append(float(list_arguments[-2]))\n",
    "                entorpy.append(float(list_arguments[-1]))\n",
    "                ## get confidence ratio\n",
    "                com = make_confidence_ratio_command(str(val_step[-1]),log_path)\n",
    "                proc = subprocess.Popen([\"/home/NAME/anaconda3/envs/py37/bin/python\"]+(com.replace('\\n','').split()), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                outp = (proc.communicate())\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(outp[0]))\n",
    "                confidence_accuracy.append(float(list_arguments[-2]))\n",
    "                confidence_ratio.append(float(list_arguments[-1]))               \n",
    "                ## get lex div\n",
    "                com = make_lexi_cmd(str(val_step[-1]),log_path)\n",
    "                proc = subprocess.Popen([\"/home/NAME/anaconda3/envs/py37/bin/python\"]+(com.replace('\\n','').split()), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                outp = (proc.communicate())\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(outp[0]))\n",
    "                unique_words.append(float(list_arguments[-2]))\n",
    "                lex_div.append(float(list_arguments[-1]))\n",
    "                ##gpt\n",
    "                ##### get gpt-original\n",
    "                com = make_gpt_command_original(str(val_step[-1]),log_path)\n",
    "                proc = subprocess.Popen(\"export CUDA_VISIBLE_DEVICES=2;/home/NAME/anaconda3/envs/py37/bin/python \" +\" \".join(com.replace('\\n','').split()), cwd='/home/NAME/PROJECT/Deep-Learning/GPT2-HarryPotter-Training/examples', stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True,  executable = '/bin/sh')\n",
    "            \n",
    "                outp = (proc.communicate())\n",
    "                list_arguments = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(outp[0]))\n",
    "                gpt_original.append(float(list_arguments[-1]))\n",
    "                #print(outp)\n",
    "                #print(float(list_arguments[-1]))\n",
    "\n",
    "\n",
    "  \n",
    "                #print(list_arguments)\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i) for i in val_step])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i) for i in bt_acc])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in sum_doc])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in maj_doc])+\"\\\",\\\",\\\")\")\n",
    "        #print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in classifier_acc])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in cls_sent])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i) for i in entorpy])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in diff_per])+\"\\\",\\\",\\\")\")\n",
    "        ##\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in confidence_accuracy])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in confidence_ratio])+\"\\\",\\\",\\\")\")\n",
    "        #gpt\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i) for i in gpt_original])+\"\\\",\\\",\\\")\")\n",
    "\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i*100) for i in lex_div])+\"\\\",\\\",\\\")\")\n",
    "        print(\"=SPLIT(\\\"\"+','.join([str(i) for i in unique_words])+\"\\\",\\\",\\\")\")\n",
    "\n",
    "\n",
    "        print(\"********************\")\n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "print(len(val_step), len(n_acc), len(bt_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0830c0239ecce94ed2ea26b5f6477db8c71c4e4cbf46bf659441f0d58889c2fd6",
   "display_name": "Python 3.7.9 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}